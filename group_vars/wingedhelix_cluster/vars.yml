---
slurm_cluster_name: 'wingedhelix'
stack_domain: ''
stack_name: "{{ slurm_cluster_name }}_cluster"  # stack_name must match the name of the folder that contains this vars.yml file.
stack_prefix: 'wh'
slurm_version: '23.02.7-2.el9.umcg'
slurm_partitions:
  - name: regular_big_vm  # Must be in sync with group listed in Ansible inventory.
    default: yes
    nodes: "{{ stack_prefix }}-node-a01"  # Must be in sync with Ansible hostnames listed in inventory.
    max_nodes_per_job: "{% if slurm_allow_jobs_to_span_nodes is defined and slurm_allow_jobs_to_span_nodes is true %}{{ groups['regular_big_vm']|list|length }}{% else %}1{% endif %}"
    max_cores_per_node: "{{ groups['regular_big_vm'] | map('extract', hostvars, 'slurm_max_cpus_per_node') | first }}"
    max_mem_per_node: "{{ groups['regular_big_vm'] | map('extract', hostvars, 'slurm_max_mem_per_node') | first }}"
    local_disk: "{{ groups['regular_big_vm'] | map('extract', hostvars, 'slurm_local_disk') | first | default(0, true) }}"
    features: "{{ groups['regular_big_vm'] | map('extract', hostvars, 'slurm_features') | first | default('none') }}"
    extra_options: 'TRESBillingWeights="CPU=1.0,Mem=0.5G" DenyQos=ds-short,ds-medium,ds-long'
  - name: user_interface  # Must be in sync with group listed in Ansible inventory.
    default: no
    nodes: "{{ slurm_cluster_name }}"  # Must be in sync with Ansible hostnames listed in inventory.
    max_nodes_per_job: 1
    max_cores_per_node: 1
    max_mem_per_node: 1024
    local_disk: "{{ groups['user_interface'] | map('extract', hostvars, 'slurm_local_disk') | first | default(0, true) }}"
    features: "{{ groups['user_interface'] | map('extract', hostvars, 'slurm_features') | first | default('none') }}"
    extra_options: 'TRESBillingWeights="CPU=1.0,Mem=1.0G" AllowQos=ds-short,ds-medium,ds-long'
slurm_qos_limit_fractions:
  regular-medium:
    group: 1
    user: 1
  regular-long:
    group: 1
    user: 1
  priority-short:
    user: 1
  priority-medium:
    group: 1
    user: 1
  priority-long:
    group: 1
    user: 1
  interactive-short:
    user: 0.5
repo_manager: 'pulp'
os_distribution: 'rocky9'
figlet_font: 'ogre'
motd: |
      =========================================================
          Welcome to {{ slurm_cluster_name | capitalize }}
      =========================================================
additional_etc_hosts:
  - group: docs_library
    nodes:
      - name: docs-on-bateleur
        network: external
  - group: betabarrel_cluster
    nodes:
      - name: betabarrel
        network: vlan16
  - group: copperfist_cluster
    nodes:
      - name: copperfist
        network: vlan16
#
# Jumphosts from other stack-name infra groups.
# We will restrict SSH login on port 22 to these jumphosts using OpenStack security rules.
#
external_jumphosts:
  - group: betabarrel_cluster
    hosts:
      - hostname: bb-porch
        network: vlan16
  - group: copperfist_cluster
    hosts:
      - hostname: cf-porch
        network: external
#
# Configure the SSH client on this stack for logins on other stacks listed in ssh_client_configs.
#
ssh_client_configs:
  - logs_library
  - betabarrel_cluster
  - copperfist_cluster
#
# Remote logging settings - for diagnostics servers
#
logs_class: 'diagnostics'
#
# Ldap settings
#
use_ldap: true
use_sssd: true
ldap_domains:
  #
  # Temporarily disabled stack LDAP, because it gets functional accounts with the same name,
  # but different UID as compared to what is available from the IDVault.
  # This results in permission denied errors due to mis-matching UIDs.
  #
  #stack:
  #  uri: "ldaps://{{ stack_prefix }}-dai"
  #  base: "dc={{ stack_name }},dc=local"
  #  schema: rfc2307bis
  #  min_id: 1000
  #  max_id: 21999
  #  user_object_class: posixAccount
  #  user_name: uid
  #  user_ssh_public_key: sshPublicKey
  #  user_member_of: groupMembership
  #  group_member: member
  #  create_ldap: true
  #  ldap_db_index: 3  # Indices up to 2 are already used by default for the "config", "monitor" and "example" databases.
  #sram:
  #  uri: "ldaps://{{ stack_prefix }}-dai"
  #  base: dc=umcg-hpc-gd,dc=services,dc=sram,dc=surf,dc=nl
  #  schema: rfc2307bis
  #  #min_id: 70000000
  #  #max_id: 72999999
  #  user_object_class: posixAccount
  #  user_name: uid
  #  user_ssh_public_key: sshPublicKey
  #  user_member_of: groupMembership
  #  group_member: member
  #  create_ldap: true
  #  ldap_db_index: 4  # Indices up to 2 are already used by default for the "config", "monitor" and "example" databases.
  #  replication_provider_uri: ldaps://ldap.sram.surf.nl
  #  replication_provider_base: dc=umcg-hpc-gd,dc=services,dc=sram,dc=surf,dc=nl
  idvault:
    uri: ldaps://svrs.id.rug.nl
    base: ou=gd,o=asds
    schema: rfc2307
    min_id: 50100000
    max_id: 55999999
    user_object_class: posixAccount
    user_name: uid
    user_ssh_public_key: sshPublicKey
    user_member_of: groupMembership
    user_expiration_date: loginExpirationTime
    group_member: memberUid
    group_object_class: groupofnames
    group_quota_soft_limit_template: ruggroupumcgquotaLFSsoft
    group_quota_hard_limit_template: ruggroupumcgquotaLFS
    listserv_mailinglist: GD
    create_ldap: false
totp:
  machines: "{{ groups['jumphost'] }}"
  excluded:
    - 'LOCAL'
    - "{{ all.ip_addresses['umcg']['net1']['address'] }}{{ all.ip_addresses['umcg']['net1']['netmask'] }}"
    - "{{ all.ip_addresses['umcg']['net2']['address'] }}{{ all.ip_addresses['umcg']['net2']['netmask'] }}"
    - "{{ all.ip_addresses['umcg']['net3']['address'] }}{{ all.ip_addresses['umcg']['net3']['netmask'] }}"
    - "{{ all.ip_addresses['umcg']['net4']['address'] }}{{ all.ip_addresses['umcg']['net4']['netmask'] }}"
cloud_image: RockyLinux-9.3_xfs
cloud_user: cloud-user
availability_zone: nova
stack_networks:
  - name: "{{ stack_prefix }}_internal_management"
    cidr: '10.10.1.0/24'
    gateway: '10.10.1.1'
    router_network: vlan16
    type: management
    external: false
  - name: "{{ stack_prefix }}_internal_storage"
    cidr: '10.10.2.0/24'
    type: storage
    external: false
  - name: vlan990
    cidr: '192.168.1.0/24'
    allow_ingress:
      - '192.168.1.0/25'
    type: storage
    external: true
  - name: vlan1068
    cidr: '172.23.60.0/24'
    allow_ingress:
      - 172.23.60.161/32  # Lustre server
      - 172.23.60.162/32  # Lustre server
      - 172.23.60.163/32  # Lustre server
      - 172.23.60.164/32  # Lustre server
    type: storage
    external: true
nameservers: [
  '8.8.4.4',  # Google DNS.
  '8.8.8.8',  # Google DNS.
]
local_admin_groups:
  - 'admin'
  - 'docker'
local_admin_users:
  - 'ger'
  - 'gerben'
  - 'henkjan'
  - 'kim'
  - 'marieke'
  - 'marloes'
  - 'max'
  - 'morris'
  - 'pieter'
  - 'robin'
  - 'sandi'
  - 'wim'
  - 'wouter'
data_transfer_only_group: 'umcg-sftp-only'
envsync_user: 'umcg-envsync'
envsync_group: 'umcg-depad'
functional_admin_group: 'umcg-funad'
functional_users_group: 'umcg-funus'  # For all functional accounts. Used in /etc/security/access.conf.
hpc_env_prefix: '/apps'
regular_groups:
# Note, for chaperone machines this is controlled in the static_inventories
  - "{{ envsync_group }}"
  - "{{ functional_admin_group }}"
  - "{{ functional_users_group }}"
  - 'umcg-atd'
  - 'umcg-gap'
  - 'umcg-gd'
  - 'umcg-genomescan'
  - 'umcg-gsad'
  - 'umcg-gst'
  - 'umcg-lab'
  - 'umcg-labgnkbh'
  - 'umcg-logstoprm'
  - 'umcg-patho'
  - 'umcg-pgx'
  - 'umcg-pr'
  - 'umcg-vipt'
regular_users:
# Note, for chaperone machines this is controlled in the static_inventories
  - user: "{{ envsync_user }}"
    groups: ["{{ envsync_group }}", "{{ functional_users_group }}"]
  - user: 'umcg-atd-ateambot'
    groups: ['umcg-atd', 'umcg-gsad', "{{ functional_users_group }}"]
  - user: 'umcg-atd-dm'
    groups: ['umcg-atd', "{{ functional_users_group }}"]
  - user: 'umcg-gap-ateambot'
    groups: ['umcg-gap', "{{ functional_users_group }}"]
  - user: 'umcg-gap-dm'
    groups: ['umcg-gap', "{{ functional_users_group }}"]
  - user: 'umcg-gd-ateambot'
    groups: ['umcg-gd', 'umcg-gap', "{{ functional_users_group }}"]
  - user: 'umcg-gd-dm'
    groups: ['umcg-gd', "{{ functional_users_group }}"]
  - user: 'umcg-genomescan-ateambot'
    groups: ['umcg-genomescan', "{{ functional_users_group }}"]
  - user: 'umcg-genomescan-dm'
    groups: ['umcg-genomescan', "{{ functional_users_group }}"]
  - user: 'umcg-gsad-ateambot'
    groups: ['umcg-gsad', "{{ functional_users_group }}"]
  - user: 'umcg-gsad-dm'
    groups: ['umcg-gsad', "{{ functional_users_group }}"]
  - user: 'umcg-gst-ateambot'
    groups: ['umcg-gst', "{{ functional_users_group }}"]
  - user: 'umcg-gst-dm'
    groups: ['umcg-gst', "{{ functional_users_group }}"]
  - user: 'umcg-lab-ateambot'
    groups: ['umcg-lab', "{{ functional_users_group }}"]
  - user: 'umcg-lab-dm'
    groups: ['umcg-lab', "{{ functional_users_group }}"]
  - user: 'umcg-labgnkbh-ateambot'
    groups: ['umcg-labgnkbh', "{{ functional_users_group }}"]
  - user: 'umcg-labgnkbh-dm'
    groups: ['umcg-labgnkbh', "{{ functional_users_group }}"]
  - user: 'umcg-logstoprm-dm'
    groups: ['umcg-logstoprm', "{{ functional_users_group }}"]
  - user: 'umcg-ogm-dm'
    groups: ['umcg-ogm', "{{ functional_users_group }}"]
  - user: 'umcg-patho-ateambot'
    groups: ['umcg-patho', "{{ functional_users_group }}"]
  - user: 'umcg-patho-dm'
    groups: ['umcg-patho', "{{ functional_users_group }}"]
  - user: 'umcg-pgx-dm'
    groups: ['umcg-pgx', "{{ functional_users_group }}"]
  - user: 'umcg-pr-ateambot'
    groups: ['umcg-pr', "{{ functional_users_group }}"]
  - user: 'umcg-pr-dm'
    groups: ['umcg-pr', "{{ functional_users_group }}"]
  - user: 'umcg-vipt-dm'
    groups: ['umcg-vipt', "{{ functional_users_group }}"]
sudoers:
  - who: ['%umcg-atd']
    become: 'umcg-atd-ateambot'
  - who: ['%umcg-atd']
    become: 'umcg-atd-dm'
  - who: ['%umcg-gap,!charbonb,!hendriksend']
    become: 'umcg-gap-ateambot'
  - who: ['%umcg-gap,!charbonb,!hendriksend']
    become: 'umcg-gap-dm'
  - who: ['%umcg-gd,!charbonb,!hendriksend']
    become: 'umcg-gd-ateambot'
  - who: ['%umcg-gd,!charbonb,!hendriksend']
    become: 'umcg-gd-dm'
  - who: ['%umcg-genomescan']
    become: 'umcg-genomescan-ateambot'
  - who: ['%umcg-genomescan']
    become: 'umcg-genomescan-dm'
  - who: ['%umcg-gsad,!charbonb,!hendriksend']
    become: 'umcg-gsad-ateambot'
  - who: ['%umcg-gsad,!charbonb,!hendriksend']
    become: 'umcg-gsad-dm'
  - who: ['%umcg-gst']
    become: 'umcg-gst-ateambot'
  - who: ['%umcg-gst']
    become: 'umcg-gst-dm'
  - who: ['%umcg-lab-dms']
    become: 'umcg-lab-ateambot'
  - who: ['%umcg-lab-dms']
    become: 'umcg-lab-dm'
  - who: ['%umcg-labgnkbh']
    become: 'umcg-labgnkbh-ateambot'
  - who: ['%umcg-labgnkbh']
    become: 'umcg-labgnkbh-dm'
  - who: ['%umcg-logstorpm']
    become: 'umcg-logstoprm-dm'
  - who: ['%umcg-ogm']
    become: 'umcg-ogm-dm'
  - who: ['%umcg-patho']
    become: 'umcg-patho-ateambot'
  - who: ['%umcg-patho']
    become: 'umcg-patho-dm'
  - who: ['%umcg-pgx']
    become: 'umcg-pgx-ateambot'
  - who: ['%umcg-pgx']
    become: 'umcg-pgx-dm'
  - who: ['%umcg-pr']
    become: 'umcg-pr-ateambot'
  - who: ['%umcg-pr']
    become: 'umcg-pr-dm'
  - who: ['%umcg-vipt']
    become: 'umcg-vipt-dm'
remote_users_in_local_groups:
  - user: 'benjaminsm'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad', 'umcg-gst',
        'umcg-gap', 'umcg-gd', 'umcg-genomescan',
        'umcg-labgnkbh', 'umcg-logstoprm', 'umcg-ogm', 'umcg-patho',
        'umcg-pgx', 'umcg-pr', 'umcg-vipt',
    ]
  - user: 'bijlsmam'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad', 'umcg-gst',
        'umcg-gap', 'umcg-gd', 'umcg-genomescan',
        'umcg-labgnkbh', 'umcg-logstoprm', 'umcg-ogm', 'umcg-patho',
        'umcg-pgx', 'umcg-pr', 'umcg-vipt',
    ]
  - user: 'charbonb'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad',
        'umcg-gap', 'umcg-gd', 'umcg-vipt',
    ]
  - user: 'cimermans'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad', 'umcg-gst',
        'umcg-gap', 'umcg-gd', 'umcg-genomescan',
        'umcg-labgnkbh', 'umcg-logstoprm', 'umcg-ogm', 'umcg-patho',
        'umcg-pgx', 'umcg-pr', 'umcg-vipt',
    ]
  - user: 'hendriksend'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad',
        'umcg-gap', 'umcg-gd', 'umcg-vipt',
    ]
  - user: 'langek'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad', 'umcg-gst',
        'umcg-gap', 'umcg-gd', 'umcg-genomescan',
        'umcg-labgnkbh', 'umcg-logstoprm', 'umcg-ogm', 'umcg-patho',
        'umcg-pgx', 'umcg-pr', 'umcg-vipt',
    ]
  - user: 'kanningaroj'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad', 'umcg-gst',
        'umcg-gap', 'umcg-gd', 'umcg-genomescan',
        'umcg-labgnkbh', 'umcg-logstoprm', 'umcg-ogm', 'umcg-patho',
        'umcg-pgx', 'umcg-pr', 'umcg-vipt',
    ]
  - user: 'neerincxp'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad', 'umcg-gst',
        'umcg-gap', 'umcg-gd', 'umcg-genomescan',
        'umcg-labgnkbh', 'umcg-logstoprm', 'umcg-ogm', 'umcg-patho',
        'umcg-pgx', 'umcg-pr', 'umcg-vipt',
    ]
  - user: 'vriesgb'
    groups: [
        "{{ envsync_group }}", 'umcg-atd', 'umcg-gsad', 'umcg-gst',
        'umcg-gap', 'umcg-gd', 'umcg-genomescan',
        'umcg-labgnkbh', 'umcg-logstoprm', 'umcg-ogm', 'umcg-patho',
        'umcg-pgx', 'umcg-pr', 'umcg-vipt',
    ]
#
## Limit the storage for specific folder, by using a loop mount of formatted file
#
soft_partitions:
  - path: /mnt/umcgst04_slice1/groups/umcg-lab/tmp07/sequencers_incoming
    src: /mnt/umcgst04_slice1/groups/umcg-lab/tmp07/sequencers_incoming.disk.img
    fstype: xfs                        # xfs and btrfs support 4k that works on sequencers
    fsopts: ' -b size=4k -s size=4k'   # extra options for 4k filesystem formatting
    size: 600                 # in GB
    user: sbsuser
    group: umcg-lab
    mode: 2770
    hostname: wh-sai
#
## Optical genome mapping
#
ogm_servers:
  - server: bas1.umcg.nl  # FQDN of OGM machine to backup.
    user: ADMINIT
    prm_location: /groups/umcg-ogm/prm67
    backup_source_dirs:
      - /home/bionano/access/web/Server/databaseFiles/molecules_files
      - /var/log
      - /home/bionano/access/web/Server/Log
      - /home/bionano/access/web/Server/anchorFiles
      - /home/ADMINIT/pg_dump
    psql_dump_location: /home/ADMINIT/pg_dump
  - server: bas3.umcg.nl  # FQDN of OGM machine to backup.
    user: ADMINIT
    prm_location: /groups/umcg-ogm/prm67
    backup_source_dirs:
      - /home/bionano/access/web/Server/databaseFiles/molecules_files
      - /var/log
      - /home/bionano/access/web/Server/Log
      - /home/bionano/access/web/Server/anchorFiles
      - /home/ADMINIT/pg_dump
    psql_dump_location: /home/ADMINIT/pg_dump
#
# Local storage variables.
#
local_mount_subfolders:
  - mount_point: '/groups'
    machines: "{{ groups['data_transfer'] }}"
    folders:
      - rel_paths:
          - "{{ data_transfer_only_group }}"
        mode: '2750'
        owner: root
        group: "{{ data_transfer_only_group }}"
      - rel_paths:
          - umcg-genomescan
          - umcg-gst
        mode: '2770'
        owner: root
#
# Shared storage related variables
#
lustre_client_networks:
  - name: tcp20
    interface: enp5s0
pfs_mounts:
  - pfs: umcgst12
    device: /dev/vdb
    source: "{{ ip_addresses[groups['nfs_server'][0]][stack_prefix + '_internal_storage']['address'] }}:/mnt"
    type: nfs4    # checked with cat /proc/filesystem
    rw_options: 'defaults,_netdev,noatime,nodiratime,local_lock=flock'
    ro_options: 'defaults,_netdev,noatime,nodiratime,ro'
    machines: "{{ groups['sys_admin_interface'] }}"
  - pfs: umcgst04/slice1
    source: '172.23.60.161@tcp20:172.23.60.162@tcp20:/'
    type: lustre
    rw_options: 'defaults,_netdev,flock,noverbose,noencrypt'
    ro_options: 'defaults,_netdev,ro,noverbose,noencrypt'
    machines: "{{ groups['sys_admin_interface'] }}"
  - pfs: 'medgen_zincfinger$'
    source: '//storage5.umcg.nl'
    type: cifs    # checked with cat /proc/filesystem
    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
    machines: "{{ groups['chaperone'] }}"
  - pfs: 'medgen_leucinezipper$'
    source: '//storage5.umcg.nl'
    type: cifs    # checked with cat /proc/filesystem
    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
    machines: "{{ groups['chaperone'] }}"
  - pfs: 'medgen_wingedhelix$'
    source: '//storage5.umcg.nl'
    type: cifs    # checked with cat /proc/filesystem
    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
    machines: "{{ groups['chaperone'] }}"
  - pfs: 'GCC'
    source: '//storage5.umcg.nl/algemenedata$/appdata/AdLas'
    type: cifs    # checked with cat /proc/filesystem
    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
    machines: "{{ groups['chaperone'] }}"
  - pfs: 'validatie-TruSightOncology-500'
    source: '//storage5.umcg.nl/path2$/archief/MolecDiagn'
    type: cifs    # checked with cat /proc/filesystem
    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
    machines: "{{ groups['chaperone'] }}"
  - pfs: 'NGSdata'
    source: '//storage5.umcg.nl/algemenedata$/appdata/BijzondereHematologie/'
    type: cifs    # checked with cat /proc/filesystem
    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
    machines: "{{ groups['chaperone'] }}"
#  - pfs: 'research$'
#    source: '//storage3.umcg.nl/'
#    type: cifs    # checked with cat /proc/filesystem
#    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
#    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
#    machines: "{{ groups['chaperone'] }}"
  - pfs: 'ogm'
    source: '//storage5.umcg.nl/algemenedata$/appdata/medgen/'
    type: cifs    # checked with cat /proc/filesystem
    rw_options: 'vers=3.0,mfsymlinks,rw,soft,perm'
    ro_options: 'vers=3.0,mfsymlinks,ro,soft,perm'
    machines: "{{ groups['chaperone'] }}"
lfs_mounts:
  - lfs: home
    pfs: umcgst12
    rw_machines: "{{ groups['cluster'] | difference(groups['nfs_server']) }}"
  - lfs: tmp07
    pfs: umcgst04/slice1
    groups:
      - name: umcg-atd
      - name: umcg-gap
      - name: umcg-gd
      - name: umcg-genomescan
      - name: umcg-gsad
      - name: umcg-gst
      - name: umcg-lab
        mode: '2750'
      - name: umcg-labgnkbh
      - name: umcg-patho
      - name: umcg-pgx
      - name: umcg-pr
      - name: umcg-vipt
    rw_machines: "{{ groups['user_interface'] + groups['deploy_admin_interface'] + groups['compute_node'] }}"
  - lfs: prm05
    pfs: 'medgen_zincfinger$'
    groups:
      - name: umcg-atd
      - name: umcg-gap
      - name: umcg-gd
      - name: umcg-gsad
      - name: umcg-logstoprm
      - name: umcg-pgx
      - name: umcg-vipt
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat05
    pfs: 'GCC'
    groups:
      - name: umcg-atd
      - name: umcg-gap
      - name: umcg-gd
      - name: umcg-genomescan
      - name: umcg-gsad
      - name: umcg-gst
      - name: umcg-vipt
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm06
    pfs: 'medgen_leucinezipper$'
    groups:
      - name: umcg-atd
      - name: umcg-gap
      - name: umcg-gd
      - name: umcg-gsad
      - name: umcg-logstoprm
      - name: umcg-pgx
      - name: umcg-vipt
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat06
    pfs: 'GCC'
    groups:
      - name: umcg-atd
      - name: umcg-gap
      - name: umcg-gd
      - name: umcg-genomescan
      - name: umcg-gsad
      - name: umcg-gst
      - name: umcg-vipt
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm07
    pfs: 'medgen_wingedhelix$'
    groups:
      - name: umcg-atd
      - name: umcg-gap
      - name: umcg-gd
      - name: umcg-gsad
      - name: umcg-logstoprm
      - name: umcg-pgx
      - name: umcg-vipt
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat07
    pfs: 'GCC'
    groups:
      - name: umcg-atd
      - name: umcg-gap
      - name: umcg-gd
      - name: umcg-genomescan
      - name: umcg-gsad
      - name: umcg-gst
      - name: umcg-vipt
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm35
    pfs: 'validatie-TruSightOncology-500'
    groups:
      - name: umcg-patho
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat35
    pfs: 'validatie-TruSightOncology-500'
    groups:
      - name: umcg-patho
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm36
    pfs: 'validatie-TruSightOncology-500'
    groups:
      - name: umcg-patho
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat36
    pfs: 'validatie-TruSightOncology-500'
    groups:
      - name: umcg-patho
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm37
    pfs: 'validatie-TruSightOncology-500'
    groups:
      - name: umcg-patho
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat37
    pfs: 'validatie-TruSightOncology-500'
    groups:
      - name: umcg-patho
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm45
    pfs: 'NGSdata'
    groups:
      - name: umcg-labgnkbh
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat45
    pfs: 'NGSdata'
    groups:
      - name: umcg-labgnkbh
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm46
    pfs: 'NGSdata'
    groups:
      - name: umcg-labgnkbh
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat46
    pfs: 'NGSdata'
    groups:
      - name: umcg-labgnkbh
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm47
    pfs: 'NGSdata'
    groups:
      - name: umcg-labgnkbh
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: dat47
    pfs: 'NGSdata'
    groups:
      - name: umcg-labgnkbh
    rw_machines: "{{ groups['chaperone'] }}"
#  - lfs: prm55
#    pfs: 'research$'
#    groups:
#      - name: umcg-pr
#    rw_machines: "{{ groups['chaperone'] }}"
#  - lfs: dat55
#    pfs: 'research$'
#    groups:
#      - name: umcg-pr
#    rw_machines: "{{ groups['chaperone'] }}"
#  - lfs: prm56
#    pfs: 'research$'
#    groups:
#      - name: umcg-pr
#    rw_machines: "{{ groups['chaperone'] }}"
#  - lfs: dat56
#    pfs: 'research$'
#    groups:
#      - name: umcg-pr
#    rw_machines: "{{ groups['chaperone'] }}"
#  - lfs: prm57
#    pfs: 'research$'
#    groups:
#      - name: umcg-pr
#    rw_machines: "{{ groups['chaperone'] }}"
#  - lfs: dat57
#    pfs: 'research$'
#    groups:
#      - name: umcg-pr
#    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: prm67
    pfs: 'ogm'
    groups:
      - name: umcg-ogm
    rw_machines: "{{ groups['chaperone'] }}"
  - lfs: env07
    pfs: umcgst12
    ro_machines: "{{ groups['compute_node'] + groups['user_interface'] }}"
    rw_machines: "{{ groups['deploy_admin_interface'] }}"
smb_server_users:
  - name: sbsuser
    uid: 501
    groups:
      - name: umcg-lab
        gid: 55100194
  - name: illumina
    uid: 502
    groups:
      - name: umcg-gap
        gid: 55100225
smb_server_interfaces: 192.168.1.0/24  # in addition to 127.0.0.1, which must always be present.
smb_server_shares:
  - name: ngs
    comment: Share for sequencers
    path: /mnt/umcgst04_slice1/groups/umcg-lab/tmp07/sequencers_incoming
    users: sbsuser
    file_mode: '0660'
    dir_mode: '0770'
    base: /mnt/umcgst04_slice1/groups/umcg-lab/tmp07  # This will not be created by the smb_server role and must already exist.
    subtree:  # This will be created if it does not already exist.
      - path: sequencers_incoming
        owner: sbsuser
        group: umcg-lab
        mode: '2770'
  - name: array
    comment: Share for array scanners
    path: /mnt/umcgst04_slice1/groups/umcg-gap/tmp07/rawdata/array/IDAT
    users: illumina
    file_mode: '0660'
    dir_mode: '0770'
    enable_acls: false
    base: /mnt/umcgst04_slice1/groups/umcg-gap/tmp07  # This will not be created by the smb_server role and must already exist.
    subtree:  # This will be created if it does not already exist.
      - path: rawdata
        owner: umcg-gap-ateambot
        group: umcg-gap
        mode: '2770'
      - path: rawdata/array
        owner: umcg-gap-ateambot
        group: umcg-gap
        mode: '2770'
      - path: rawdata/array/IDAT
        owner: illumina
        group: umcg-gap
        mode: '2770'
...
