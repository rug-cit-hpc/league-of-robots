---
slurm_cluster_name: 'hyperchicken'
stack_domain: ''
stack_name: "{{ slurm_cluster_name }}_cluster"  # stack_name must match the name of the folder that contains this vars.yml file.
stack_prefix: 'hc'
slurm_version: '22.05.2-1.el7.umcg'
slurm_partitions:
  - name: regular  # Must be in sync with group listed in Ansible inventory.
    default: yes
    nodes: "{{ stack_prefix }}-vcompute[01]"  # Must be in sync with Ansible hostnames listed in inventory.
    max_nodes_per_job: "{% if slurm_allow_jobs_to_span_nodes is defined and slurm_allow_jobs_to_span_nodes is true %}{{ groups['regular']|list|length }}{% else %}1{% endif %}"
    max_cores_per_node: "{{ groups['regular'] | map('extract', hostvars, 'slurm_max_cpus_per_node') | first }}"
    max_mem_per_node: "{{ groups['regular'] | map('extract', hostvars, 'slurm_max_mem_per_node') | first }}"
    local_disk: "{{ groups['regular'] | map('extract', hostvars, 'slurm_local_disk') | first | default(0, true) }}"
    features: "{{ groups['regular'] | map('extract', hostvars, 'slurm_features') | first | default('none') }}"
    extra_options: 'TRESBillingWeights="CPU=1.0,Mem=0.5G" DenyQos=ds-short,ds-medium,ds-long'
  - name: user_interface  # Must be in sync with group listed in Ansible inventory.
    default: no
    nodes: "{{ slurm_cluster_name }}"  # Must be in sync with Ansible hostnames listed in inventory.
    max_nodes_per_job: 1
    max_cores_per_node: 1
    max_mem_per_node: 1024
    local_disk: "{{ groups['user_interface'] | map('extract', hostvars, 'slurm_local_disk') | first | default(0, true) }}"
    features: "{{ groups['user_interface'] | map('extract', hostvars, 'slurm_features') | first | default('none') }}"
    extra_options: 'TRESBillingWeights="CPU=1.0,Mem=1.0G" AllowQos=ds-short,ds-medium,ds-long'
repo_manager: 'pulp'
os_distribution: 'centos7'
figlet_font: 'lockergnome'
motd: "To solve or not to solve, that's the question."
additional_etc_hosts:
  - group: docs_library
    nodes:
      - name: docs-on-bateleur
        network: external
  - group: donbot_azure
    nodes:
      - name: ladap
        network: donbot_external_network
#
# Remote logging settings - for diagnostics servers
#
logs_class: 'development'
#
# Ldap settings
#
use_ldap: true
use_sssd: true
ldap_domains:
  stack:
    uri: "ldaps://{{ stack_prefix }}-dai"
    base: "dc={{ stack_name }},dc=local"
    schema: rfc2307bis
    min_id: 1000
    max_id: 21999
    user_object_class: posixAccount
    user_name: uid
    user_ssh_public_key: sshPublicKey
    user_member_of: memberOf
    group_member: member
    create_ldap: true
    ldap_db_index: 3  # Indices up to 2 are already used by default for the "config", "monitor" and "example" databases.
cloud_image: CentOS7-Cloud
cloud_user: centos
availability_zone: nova
stack_networks:
  - name: "{{ stack_prefix }}_internal_management"
    cidr: '10.10.1.0/24'
    gateway: '10.10.1.1'
    router_network: public
    type: management
    external: false
  - name: subnet-nfs-data-2541
    cidr: '10.35.141.0/24'
    allow_ingress:
      - 10.35.141.251/32  # NFS server
      - 10.35.141.252/32  # NFS server
      - 10.35.141.253/32  # NFS server
    type: storage
    external: true
nameservers: [
  '8.8.4.4',  # Google DNS.
  '8.8.8.8',  # Google DNS.
]
local_admin_groups:
  - 'admin'
local_admin_users:
  - 'gerben'
  - 'marieke'
  - 'marloes'
  - 'pieter'
  - 'sandi'
envsync_user: 'envsync'
envsync_group: 'depad'
functional_admin_group: 'funad'
hpc_env_prefix: '/apps'
regular_groups:
  - "{{ envsync_group }}"
  - "{{ functional_admin_group }}"
  - 'users'
  - 'solve-rd'
  - 'umcg-atd'
  - 'umcg-gsad'
regular_users:
  - user: "{{ envsync_user }}"
    groups: ["{{ envsync_group }}"]
  - user: 'solve-rd-dm'
    groups: ['solve-rd']
  - user: 'umcg-atd-dm'
    groups: ['umcg-atd']
  - user: 'umcg-gsad-dm'
    groups: ['umcg-gsad']
  - user: 'gvdvries'
    groups: ['users', "{{ envsync_group }}", 'umcg-atd', 'solve-rd']
  - user: 'mbijlsma'
    groups: ['users', "{{ envsync_group }}", 'umcg-atd', 'solve-rd']
  - user: 'mswertz'
    groups: ['users', "{{ envsync_group }}", 'umcg-atd', 'solve-rd']
  - user: 'pneerincx'
    groups: ['users', "{{ envsync_group }}", 'umcg-atd', 'solve-rd']
  - user: 'rkanninga'
    groups: ['users', "{{ envsync_group }}", 'umcg-atd', 'solve-rd']
  - user: 'scimerman'
    groups: ['users', "{{ envsync_group }}", 'umcg-atd', 'solve-rd']
  - user: 'mbenjamins'
    groups: ['users', "{{ envsync_group }}", 'umcg-atd', 'solve-rd']
  - user: 'umcg-molgenis'
    groups: ['users', 'umcg-atd', 'umcg-gsad']
sudoers:
  - who: ['%solve-rd']
    become: 'solve-rd-dm'
  - who: ['%umcg-atd']
    become: 'umcg-atd-dm'
  - who: ['%umcg-gsad']
    become: 'umcg-gsad-dm'
#
# Shared storage related variables
#
pfs_mounts:
  - pfs: ecst01
    source: '10.35.141.253:/solve-rd-98599485'
    type: nfs4
    rw_options: 'defaults,_netdev,noatime,nodiratime,rw'
    ro_options: 'defaults,_netdev,noatime,nodiratime,ro'
    machines: "{{ groups['sys_admin_interface'] }}"
lfs_mounts:
  - lfs: home
    pfs: ecst01
    rw_machines: "{{ groups['cluster'] }}"
  - lfs: tmp09
    pfs: ecst01
    groups:
      - name: umcg-atd
      - name: solve-rd
      - name: umcg-gsad
    rw_machines: "{{ groups['user_interface'] + groups['deploy_admin_interface'] + groups['compute_node'] }}"
  - lfs: prm09
    pfs: ecst01
    groups:
      - name: umcg-atd
      - name: solve-rd
      - name: umcg-gsad
    rw_machines: "{{ groups['user_interface'] }}"
  - lfs: env09
    pfs: ecst01
    ro_machines: "{{ groups['compute_node'] + groups['user_interface'] }}"
    rw_machines: "{{ groups['deploy_admin_interface'] }}"
ega_fuse_client_mounts:
  solve_rd: '/groups/solve-rd/prm09/ega-fuse-client'
ega_fuse_client_java_home: '/etc/alternatives/jre_11_openjdk'
interfaces:
  - device: 'eth0'
    bootproto: 'dhcp'
  - device: 'eth1' 
    bootproto: 'dhcp'
...
